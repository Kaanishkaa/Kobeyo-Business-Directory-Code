{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5da393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 1: Setup and Loading Data\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import threading\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6282d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading all business data from 'business_directory_cleaned.csv'...\n",
      "‚úÖ Loaded and prepared to analyze all 34 websites.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "INPUT_FILENAME = 'business_directory_cleaned.csv'\n",
    "OUTPUT_KEYWORDS_FILENAME = 'catering_keyword_dictionary_full.json'\n",
    "\n",
    "# --- Load Data (No Sampling) ---\n",
    "print(f\"üöÄ Loading all business data from '{INPUT_FILENAME}'...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILENAME)\n",
    "    if 'Company Website' not in df.columns:\n",
    "        raise ValueError(\"The required column 'Company Website' was not found in the CSV.\")\n",
    "    \n",
    "    # Drop rows where the website URL is missing or invalid\n",
    "    df.dropna(subset=['Company Website'], inplace=True)\n",
    "    df = df[df['Company Website'].str.startswith('http', na=False)]\n",
    "    \n",
    "    # Create the final list of all URLs to be processed\n",
    "    website_urls = df['Company Website'].tolist()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded and prepared to analyze all {len(website_urls)} websites.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: The file '{INPUT_FILENAME}' was not found.\")\n",
    "    website_urls = []\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå ERROR: {e}\")\n",
    "    website_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e2d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: AI Keyword Extraction Logic\n",
    "# ==============================================================================\n",
    "\n",
    "# Initialize the Language Model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Define the prompt template for the AI\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert market research analyst for the food and beverage industry. \n",
    "The following is the text content scraped from a single company's website.\n",
    "\n",
    "Your task is to analyze this text and identify specific keywords and short phrases (2-3 words) that strongly indicate the company offers CATERING services.\n",
    "\n",
    "Please provide your output as a single, clean JSON object with one key, \"keywords\". \n",
    "If you find no relevant keywords, return an empty list.\n",
    "\n",
    "- Focus on service-related terms (e.g., \"corporate catering\", \"wedding events\").\n",
    "- Exclude generic business terms like 'contact us', 'about us', 'our menu', 'gallery', 'home', and copyright notices.\n",
    "- Base your answer *only* on the text provided.\n",
    "\n",
    "Here is the website content:\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\"\"\")\n",
    "\n",
    "# Define the analysis chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "def analyze_website_for_keywords(url: str) -> list:\n",
    "    \"\"\"\n",
    "    Uses LangChain to scrape a website and sends the content to an LLM\n",
    "    to extract keywords. Returns a list of keywords.\n",
    "    \"\"\"\n",
    "    print(f\"  -> Analyzing: {url}\")\n",
    "    try:\n",
    "        # Use the loader in its simplest, most robust form.\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths=(url,),\n",
    "            requests_kwargs={\"headers\": {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}}\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        \n",
    "        if not docs:\n",
    "            print(f\"  -  WARNING: Could not load any content from {url}\")\n",
    "            return []\n",
    "        \n",
    "        website_content = \"\\n\".join([doc.page_content for doc in docs])\n",
    "        \n",
    "        if not website_content.strip():\n",
    "            print(f\"  -  WARNING: Loaded page from {url} but found no text content.\")\n",
    "            return []\n",
    "\n",
    "        # Invoke the chain with the scraped content.\n",
    "        response_str = chain.invoke({\"context\": website_content})\n",
    "        \n",
    "        # Parse the JSON response from the LLM.\n",
    "        try:\n",
    "            if response_str.startswith(\"```json\"):\n",
    "                response_str = response_str.strip(\"```json\").strip()\n",
    "            \n",
    "            response_json = json.loads(response_str)\n",
    "            keywords = response_json.get(\"keywords\", [])\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"  -  WARNING: LLM did not return valid JSON. Response: {response_str}\")\n",
    "            return []\n",
    "        \n",
    "        if isinstance(keywords, list):\n",
    "            print(f\"  -  Found keywords: {keywords}\")\n",
    "            return keywords\n",
    "        else:\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  -  ERROR analyzing {url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e7c5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting AI analysis for all 34 websites. This may take some time...\n",
      "  -> Analyzing: http://www.marbled.la/\n",
      "  -> Analyzing: https://goodheartcatering.com/\n",
      "  -> Analyzing: https://luxebites.com/\n",
      "  -> Analyzing: https://www.cratefulcatering.com/\n",
      "  -> Analyzing: https://www.bitecatering.net/\n",
      "  -  ERROR analyzing http://www.marbled.la/: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "  -> Analyzing: https://chubscatering.com/\n",
      "  -  Found keywords: ['corporate events', 'wedding menus', 'crew meals', 'beverage service', 'wedding catering', 'corporate catering', 'production catering', 'bar mitzvah catering', 'kosher catering', 'beverage catering services']\n",
      "  -> Analyzing: http://alohacateringservicesinc.com/\n",
      "  -  Found keywords: ['catering company', 'intimate gatherings', 'large, high-end events', 'customized menus', 'corporate events', 'holiday parties', 'weddings', 'rehearsal dinners', 'baby showers', 'nonprofit events', 'church events', 'full-service']\n",
      "  -> Analyzing: https://heirloomla.com/\n",
      "  -  Found keywords: ['corporate events', 'office meetings', 'drop-off catering', 'corporate breakfast meeting', 'office lunch', 'large company event', 'business and office catering', 'non profit catering service', 'university catering service', 'medical sales catering service', 'destination management catering service']\n",
      "  -> Analyzing: https://losangelestacoscatering.com/\n",
      "  -  Found keywords: ['corporate catering', 'wedding catering', 'social catering', 'catered events', 'event producers', 'catering services', 'catering experience', 'catering solutions', 'catering partner', 'catering market']\n",
      "  -> Analyzing: http://www.spottedhencatering.com/\n",
      "  -  WARNING: Loaded page from http://alohacateringservicesinc.com/ but found no text content.\n",
      "  -> Analyzing: https://www.feliceitaliancatering.com/\n",
      "  -  Found keywords: ['wedding menus', 'drop off party catering', 'production catering', 'corporate catering', 'drop-off parties/events']\n",
      "  -> Analyzing: https://www.robertscateringservice.com/\n",
      "  -  Found keywords: ['Event Catering', 'Corporate & Production Catering', 'Bar Catering', 'Smoothie Catering', 'wedding catering', 'small party catering', 'event catering services', 'wedding and event caterer', 'corporate events']\n",
      "  -> Analyzing: http://www.tgiscatering.com/\n",
      "  -  Found keywords: ['catering services', 'corporate function', 'food catering services', 'custom event packages', 'events catered', 'customizable packages']\n",
      "  -> Analyzing: http://bitesandbashes.com/\n",
      "  -  Found keywords: ['brunch buffet', 'fundraiser at The Paramour', 'cooking class', 'vegan garden dinner', 'book signing parties', 'beach party buffet', 'ladies luncheon', 'family style service', 'wedding in Ojai', 'dinner party', 'family lunch buffet']\n",
      "  -> Analyzing: https://basilpizzabar.com/\n",
      "  -  Found keywords: ['pizza catering', 'corporate events', 'private events', 'wedding events', 'wood-fired pizza catering', 'catering setups', 'buffet style', 'family style', 'individual guest ordering', 'cater our wedding', 'catering menu', 'catering your special event']\n",
      "  -> Analyzing: http://www.hcmenu.com/\n",
      "  -  Found keywords: ['catering service', 'event planning', 'social events', 'weddings', 'corporate events', 'luxury events', 'executive-level events']\n",
      "  -> Analyzing: http://www.schafferla.com/\n",
      "  -  Found keywords: ['Mobile Pizza Catering', 'Artisan Pizza Catering', 'Los Angeles Pizza Catering', 'Indoor pizza catering', 'Basil Pizza Catering Experience', 'Wedding Pizza Catering', 'custom catering menus', 'Live Action Station', 'Live pizza station catering', 'Home Event Catering']\n",
      "  -> Analyzing: https://simoncaterers.com/\n",
      "  -  Found keywords: ['catering and events', 'full-service offerings', 'corporate lunch setups', 'interactive stations', 'plated dinners', 'event coordinators', 'corporate events', 'private events', 'non-profit galas', 'intimate dinner parties', 'weddings', 'holiday parties']\n",
      "  -> Analyzing: http://www.kmichellekitchencatering.com/\n",
      "  -  Found keywords: ['full-service catering', 'special event venues', 'wedding planning', 'wedding catering', 'corporate catering', 'private catering', 'entertainment catering']\n",
      "  -> Analyzing: https://www.ask4tacos.com/\n",
      "  -  Found keywords: ['Catering and Special Events', 'event catering', 'special events']\n",
      "  -> Analyzing: http://www.paulinasfoodcatering.com/\n",
      "  -  WARNING: Loaded page from http://www.paulinasfoodcatering.com/ but found no text content.\n",
      "  -> Analyzing: http://www.offtheshelfcatering.com/\n",
      "  -  Found keywords: ['corporate catering', 'wedding events', 'hospitality, events and catering', 'event services', 'catering and event services', 'execute events', 'event & staffing flow', 'service events']\n",
      "  -> Analyzing: https://hautechefsla.com/\n",
      "  -  Found keywords: ['wedding catering', 'corporate caterers', 'occasions catering', 'catering styles', 'sushi catering', 'charcuterie board designs catering', 'taco catering', 'breakfast and brunch catering', 'premium catering service', 'catering services in Los Angeles', 'fully customized catering', 'catering service offerings', 'event catering', 'corporate catering services', 'catering for any dietary needs']\n",
      "  -> Analyzing: http://www.castlescatering.com/\n",
      "  -  Found keywords: ['Corporate Catering', 'Event Catering', 'Wedding Catering', 'catering services', 'cater your next event', 'catering for any occasion', 'catered special events', 'corporate office parties', 'catering for all']\n",
      "  -> Analyzing: http://www.laloscatering.com/\n",
      "  -  Found keywords: ['event dining', 'production catering', 'bespoke culinary services', 'unique dining experiences']\n",
      "  -> Analyzing: http://www.karlascoffeecart.com/\n",
      "  -  Found keywords: ['set catering', 'production catering', 'full catering option', 'film and TV catering', 'commercial catering']\n",
      "  -> Analyzing: http://www.emunainc.com/\n",
      "  -  Found keywords: ['Private Dinner Catering', 'Business Lunch Catering', 'Catering Your Next Event', 'private and corporate events', 'Corporate Events']\n",
      "  -> Analyzing: https://www.tasteandcompany.com/\n",
      "  -  Found keywords: ['international catering', 'party trays', 'breakfast packages', 'lunch packages', 'dinner packages', 'banquets', 'catering to LA']\n",
      "  -> Analyzing: http://alfredocatering.net/\n",
      "  -  Found keywords: []\n",
      "  -> Analyzing: http://catering4seasons.com/\n",
      "  -  Found keywords: ['corporate catering', 'wedding events', 'special occasion', 'event consulting', 'gourmet to go', 'order catering', 'plan your event', 'event planning']\n",
      "  -> Analyzing: http://www.syrcatering.com/\n",
      "  -  Found keywords: ['full service catering', 'large scale full service catering', 'festivals catering', 'production catering', 'private events', 'corporate events', 'weddings']\n",
      "  -> Analyzing: http://www.tresla.com/\n",
      "  -  Found keywords: ['fusion catering', 'private events', 'corporate events', 'weddings', 'galas']\n",
      "  -> Analyzing: https://www.laspicecatering.com/\n",
      "  -  Found keywords: ['Tres LA Catering', 'event experience', 'wedding day', 'catering company']\n",
      "  -> Analyzing: https://www.thebutlerpantrycateringco.com/\n",
      "  -  Found keywords: ['corporate events', 'private parties', 'weddings', 'event planning', 'drop-off catering']\n",
      "  -  Found keywords: ['full service catering', 'event planning', 'corporate events', 'intimate dinner party', 'larger gathering', 'company holiday party', 'catering services', 'business function']\n",
      "  -  Found keywords: ['food catering for events', 'preferred catering company', 'catering services', 'catering menus', 'food catering services', 'catering business', 'catering for all kinds of events', 'small casual gathering', 'huge wedding']\n",
      "  -  Found keywords: ['corporate banquets', 'wedding events', 'birthday parties', 'anniversarys', 'school breakfast/lunch programs', 'senior meals', 'PR firms', 'event catering', 'custom catering', 'catering booking form', 'film & catering menus']\n",
      "  -  Found keywords: []\n",
      "\n",
      "‚úÖ AI analysis complete for all websites.\n",
      "\n",
      "üéâ Success! Keyword dictionary created and saved to 'catering_keyword_dictionary_full.json'.\n",
      "\n",
      "--- Final Catering Keywords ---\n",
      "- Event Catering\n",
      "- catering company\n",
      "- catering services\n",
      "- corporate catering\n",
      "- corporate events\n",
      "- drop-off catering\n",
      "- event catering\n",
      "- event planning\n",
      "- food catering services\n",
      "- full service catering\n",
      "- holiday parties\n",
      "- private events\n",
      "- production catering\n",
      "- wedding catering\n",
      "- wedding events\n",
      "- wedding menus\n",
      "- weddings\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3: Run Analysis at Scale and Create Final Dictionary\n",
    "# ==============================================================================\n",
    "\n",
    "all_extracted_keywords = []\n",
    "\n",
    "if 'website_urls' in locals() and website_urls and os.environ.get(\"OPENAI_API_KEY\") != \"YOUR_OPENAI_API_KEY_HERE\":\n",
    "    print(f\"\\nüöÄ Starting AI analysis for all {len(website_urls)} websites. This may take some time...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_url = {executor.submit(analyze_website_for_keywords, url): url for url in website_urls}\n",
    "        \n",
    "        for future in as_completed(future_to_url):\n",
    "            try:\n",
    "                keywords = future.result()\n",
    "                if keywords:\n",
    "                    all_extracted_keywords.extend(keywords)\n",
    "            except Exception as exc:\n",
    "                print(f\"‚ùå An error occurred for URL {future_to_url[future]}: {exc}\")\n",
    "\n",
    "    print(\"\\n‚úÖ AI analysis complete for all websites.\")\n",
    "    \n",
    "    # --- Process and save the final keyword dictionary ---\n",
    "    if all_extracted_keywords:\n",
    "        # Count the occurrences of each keyword\n",
    "        keyword_counts = Counter(all_extracted_keywords)\n",
    "        \n",
    "        # Only keep keywords that appeared on at least 2 different websites\n",
    "        MINIMUM_OCCURRENCES = 2\n",
    "        \n",
    "        final_keywords = sorted([\n",
    "            keyword for keyword, count in keyword_counts.items() \n",
    "            if count >= MINIMUM_OCCURRENCES\n",
    "        ])\n",
    "        \n",
    "        # Create the final dictionary structure\n",
    "        keyword_dictionary = {\n",
    "            \"Catering\": {\n",
    "                \"skill_id\": 11,\n",
    "                \"keywords\": final_keywords\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save the dictionary to a JSON file\n",
    "        with open(OUTPUT_KEYWORDS_FILENAME, 'w') as f:\n",
    "            json.dump(keyword_dictionary, f, indent=4)\n",
    "            \n",
    "        print(f\"\\nüéâ Success! Keyword dictionary created and saved to '{OUTPUT_KEYWORDS_FILENAME}'.\")\n",
    "        print(\"\\n--- Final Catering Keywords ---\")\n",
    "        for keyword in final_keywords:\n",
    "            print(f\"- {keyword}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No keywords were extracted from any of the websites.\")\n",
    "\n",
    "elif not os.environ.get(\"OPENAI_API_KEY\") or os.environ.get(\"OPENAI_API_KEY\") == \"YOUR_OPENAI_API_KEY_HERE\":\n",
    "    print(\"\\n‚ùå ERROR: Please set your OpenAI API key in Cell 1 before running.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No URLs were loaded. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8404dc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading keyword dictionary from 'catering_keyword_dictionary.json'...\n",
      "‚úÖ Successfully loaded 8 keywords for Skill ID 11.\n",
      "\n",
      "üöÄ Loading business data from 'business_directory_cleaned.csv'...\n",
      "‚úÖ Loaded 34 businesses with valid websites to be processed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# Cell 1: Configuration and Loading Inputs\n",
    "# ==============================================================================\n",
    "\n",
    "# --- File Configuration ---\n",
    "# The original CSV with all your businesses\n",
    "INPUT_BUSINESS_FILENAME = 'business_directory_cleaned.csv' \n",
    "\n",
    "# The keyword dictionary file you just created with the AI\n",
    "INPUT_KEYWORDS_FILENAME = 'catering_keyword_dictionary.json'\n",
    "\n",
    "# The final, enriched output file\n",
    "OUTPUT_FILENAME = 'final_tagged_businesses.csv'\n",
    "\n",
    "# --- Load Keyword Dictionary ---\n",
    "print(f\"üöÄ Loading keyword dictionary from '{INPUT_KEYWORDS_FILENAME}'...\")\n",
    "try:\n",
    "    with open(INPUT_KEYWORDS_FILENAME, 'r') as f:\n",
    "        keyword_dict = json.load(f)\n",
    "    \n",
    "    # Extract the keywords and skill ID for the 'Catering' category\n",
    "    catering_info = keyword_dict.get('Catering', {})\n",
    "    CATERING_KEYWORDS = catering_info.get('keywords', [])\n",
    "    CATERING_SKILL_ID = catering_info.get('skill_id')\n",
    "\n",
    "    if not CATERING_KEYWORDS or not CATERING_SKILL_ID:\n",
    "        raise ValueError(\"Keywords or skill_id for 'Catering' not found in JSON file.\")\n",
    "        \n",
    "    print(f\"‚úÖ Successfully loaded {len(CATERING_KEYWORDS)} keywords for Skill ID {CATERING_SKILL_ID}.\")\n",
    "\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"‚ùå ERROR: Could not load or parse the keyword dictionary. {e}\")\n",
    "    CATERING_KEYWORDS = [] # Ensure the script doesn't fail later\n",
    "\n",
    "# --- Load Business Data ---\n",
    "print(f\"\\nüöÄ Loading business data from '{INPUT_BUSINESS_FILENAME}'...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_BUSINESS_FILENAME)\n",
    "    df.dropna(subset=['Company Website'], inplace=True)\n",
    "    df = df[df['Company Website'].str.startswith('http', na=False)]\n",
    "    print(f\"‚úÖ Loaded {len(df)} businesses with valid websites to be processed.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: The file '{INPUT_BUSINESS_FILENAME}' was not found.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64ee9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: Scraper and Tagger Function\n",
    "# ==============================================================================\n",
    "\n",
    "def scrape_and_find_matches(url: str, keywords_to_find: list):\n",
    "    \"\"\"\n",
    "    Scrapes a single URL and checks its text against a list of keywords.\n",
    "    Returns the list of keywords that were found.\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # We can use a simple requests-based scraper here, as we don't need to handle complex JS\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code != 200:\n",
    "            return []\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        page_text = soup.get_text(\" \", strip=True).lower()\n",
    "        \n",
    "        # Find all keywords from our list that are present in the page text\n",
    "        matched_keywords = [\n",
    "            keyword for keyword in keywords_to_find \n",
    "            if keyword.lower() in page_text\n",
    "        ]\n",
    "        \n",
    "        return matched_keywords\n",
    "        \n",
    "    except requests.RequestException:\n",
    "        # If the website is down or fails to load, return an empty list\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84168d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting tagging process for all 34 businesses...\n",
      "  -> Processing: Marbled LA\n",
      "  -> Processing: Good Heart Catering\n",
      "  -> Processing: Luxe Bites - LA's Best Charcuterie Boards and Event Catering\n",
      "  -> Processing: Crateful Catering Los Angeles\n",
      "  -> Processing: Bite Catering Couture\n",
      "  -> Processing: Chubby Fingers Catering Co\n",
      "  -> Processing: Aloha Catering Services Inc\n",
      "  -> Processing: Heirloom LA\n",
      "  -> Processing: Las Hermanas Catering\n",
      "  -> Processing: Spotted Hen Catering\n",
      "  -> Processing: Felice Italian Catering\n",
      "  -> Processing: Robert's Catering Services\n",
      "  -> Processing: TGIS Catering Services\n",
      "  -> Processing: Bites and Bashes Catering\n",
      "  -> Processing: Basil Pizza Bar Catering\n",
      "  -> Processing: The Daily by HC\n",
      "  -> Processing: Schaffer\n",
      "  -> Processing: Simon's Caterers\n",
      "  -> Processing: K Michelle's Kitchen Catering\n",
      "  -> Processing: Ask 4 Tacos Catering\n",
      "  -> Processing: Paulina's Catering\n",
      "  -> Processing: OFF THE SHELF CATERING\n",
      "  -> Processing: Haute Chefs Los Angeles\n",
      "  -> Processing: Castle's Southern and Creole Catering\n",
      "  -> Processing: Lalo's Catering Company\n",
      "  -> Processing: Karla's Coffee Cart Catering\n",
      "  -> Processing: Catering by Emuna\n",
      "  -> Processing: Taste And Company\n",
      "  -> Processing: Alfredo Catering Inc\n",
      "  -> Processing: Four Seasons Catering\n",
      "  -> Processing: Serves You Right! Catering\n",
      "  -> Processing: Tr√®s LA Catering\n",
      "  -> Processing: LA Spice Catering\n",
      "  -> Processing: Team Butler Inc. (DBA) The Butler Pantry Catering Co.\n",
      "\n",
      "üéâ Success! Enriched data saved to 'final_tagged_businesses.csv'.\n",
      "\n",
      "--- Sample of Final Output ---\n",
      "                                         Company Name  \\\n",
      "0                                          Marbled LA   \n",
      "10                            Felice Italian Catering   \n",
      "1                                 Good Heart Catering   \n",
      "5                          Chubby Fingers Catering Co   \n",
      "4                               Bite Catering Couture   \n",
      "3                       Crateful Catering Los Angeles   \n",
      "14                           Basil Pizza Bar Catering   \n",
      "9                                Spotted Hen Catering   \n",
      "2   Luxe Bites - LA's Best Charcuterie Boards and ...   \n",
      "7                                         Heirloom LA   \n",
      "\n",
      "                                     Matched_Keywords Skill_ID  \n",
      "0                                                               \n",
      "10                                   corporate events       11  \n",
      "1                 catering services, corporate events       11  \n",
      "5                                    corporate events       11  \n",
      "4   catering solutions, corporate catering, weddin...       11  \n",
      "3   catering services, corporate catering, corpora...       11  \n",
      "14                                                              \n",
      "9                                 production catering       11  \n",
      "2   catering services, corporate events, event pla...       11  \n",
      "7                                                               \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3: Main Processing Logic\n",
    "# ==============================================================================\n",
    "\n",
    "def process_business_row(row_tuple):\n",
    "    \"\"\"\n",
    "    Worker function that takes a row, scrapes the website, finds matches,\n",
    "    and returns the updated row information.\n",
    "    \"\"\"\n",
    "    index, row_data = row_tuple\n",
    "    company_name = row_data['Company Name']\n",
    "    website_url = row_data['Company Website']\n",
    "    \n",
    "    print(f\"  -> Processing: {company_name}\")\n",
    "    \n",
    "    # Scrape the website and get a list of any keywords that matched\n",
    "    matched_keywords = scrape_and_find_matches(website_url, CATERING_KEYWORDS)\n",
    "    \n",
    "    # Create the new columns based on the results\n",
    "    if matched_keywords:\n",
    "        # Join the list of matched keywords into a single string\n",
    "        row_data['Matched_Keywords'] = \", \".join(matched_keywords)\n",
    "        row_data['Skill_ID'] = CATERING_SKILL_ID\n",
    "    else:\n",
    "        row_data['Matched_Keywords'] = \"\"\n",
    "        row_data['Skill_ID'] = \"\"\n",
    "        \n",
    "    return row_data\n",
    "\n",
    "# --- Main execution block ---\n",
    "if df is not None and CATERING_KEYWORDS:\n",
    "    print(f\"\\nüöÄ Starting tagging process for all {len(df)} businesses...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Use ThreadPoolExecutor to process rows in parallel for speed\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # We pass df.iterrows() which gives us both the index and the row data\n",
    "        future_to_name = {\n",
    "            executor.submit(process_business_row, row_tuple): row_tuple[1]['Company Name'] \n",
    "            for row_tuple in df.iterrows()\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(future_to_name):\n",
    "            try:\n",
    "                # The result is the updated row (as a dictionary)\n",
    "                updated_row = future.result()\n",
    "                all_results.append(updated_row)\n",
    "            except Exception as exc:\n",
    "                print(f\"‚ùå An error occurred for business {future_to_name[future]}: {exc}\")\n",
    "\n",
    "    # --- Save the final enriched DataFrame ---\n",
    "    if all_results:\n",
    "        # Create a new DataFrame from the list of updated row dictionaries\n",
    "        final_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Reorder columns to have the new ones at the end\n",
    "        original_cols = [col for col in df.columns if col in final_df.columns]\n",
    "        new_cols = ['Matched_Keywords', 'Skill_ID']\n",
    "        final_df = final_df[original_cols + new_cols]\n",
    "        \n",
    "        final_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "        print(f\"\\nüéâ Success! Enriched data saved to '{OUTPUT_FILENAME}'.\")\n",
    "        \n",
    "        # Display a sample of the results\n",
    "        print(\"\\n--- Sample of Final Output ---\")\n",
    "        print(final_df[['Company Name', 'Matched_Keywords', 'Skill_ID']].head(10))\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No businesses were processed.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Script did not run. Check that both input files are available and correctly configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272a9325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to business_emails.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "# Google Places API setup\n",
    "API_KEY = 'AIzaSyCpnXVIbUNCZTfTt7xoihkGt14SgCmaYxw'  # Replace with your Google Places API key\n",
    "query = 'pizzeria in LA'\n",
    "url = f'https://maps.googleapis.com/maps/api/place/textsearch/json?query={query}&key={API_KEY}'\n",
    "\n",
    "# Fetch business data from Google Places API\n",
    "def get_business_websites(query):\n",
    "    try:\n",
    "        response = requests.get(f'https://maps.googleapis.com/maps/api/place/textsearch/json?query={query}&key={API_KEY}')\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        websites = [result.get('website') for result in data.get('results', []) if 'website' in result]\n",
    "        return [w for w in websites if w]  # Filter out None or empty websites\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching business data: {e}\")\n",
    "        return []\n",
    "\n",
    "# Extract emails from a webpage\n",
    "def extract_emails(url, max_pages=10):\n",
    "    emails = set()\n",
    "    visited_urls = set()\n",
    "    urls_to_visit = {url}\n",
    "    \n",
    "    while urls_to_visit and len(visited_urls) < max_pages:\n",
    "        current_url = urls_to_visit.pop()\n",
    "        if current_url in visited_urls:\n",
    "            continue\n",
    "        visited_urls.add(current_url)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(current_url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract emails from page text\n",
    "            text = soup.get_text()\n",
    "            found_emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "            emails.update(found_emails)\n",
    "            \n",
    "            # Find links to other pages on the same domain\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                if urlparse(full_url).netloc == urlparse(url).netloc:\n",
    "                    urls_to_visit.add(full_url)\n",
    "                    \n",
    "            time.sleep(1)  # Respectful scraping delay\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {current_url}: {e}\")\n",
    "    \n",
    "    return list(emails)\n",
    "\n",
    "# Predefined patterns for classification\n",
    "hr_patterns = ['hr@', 'careers@', 'jobs@', 'humanresources@']\n",
    "sales_patterns = ['sales@', 'business@', 'info@', 'contact@']\n",
    "\n",
    "# Classify emails based on patterns\n",
    "def classify_email(email):\n",
    "    email_lower = email.lower()\n",
    "    if any(pattern in email_lower for pattern in hr_patterns):\n",
    "        return 'HR'\n",
    "    elif any(pattern in email_lower for pattern in sales_patterns):\n",
    "        return 'Sales'\n",
    "    return 'Other'\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    websites = get_business_websites(query)\n",
    "    results = []\n",
    "    \n",
    "    for website in websites:\n",
    "        print(f\"Scraping {website}...\")\n",
    "        emails = extract_emails(website)\n",
    "        for email in emails:\n",
    "            category = classify_email(email)\n",
    "            results.append({'website': website, 'email': email, 'category': category})\n",
    "    \n",
    "    # Save results to CSV\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('business_emails.csv', index=False)\n",
    "    print(\"Results saved to business_emails.csv\")\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c37ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
