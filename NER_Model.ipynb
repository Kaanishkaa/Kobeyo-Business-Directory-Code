{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BabQdcysrvfh",
        "outputId": "3be6bb4a-f331-41c0-9219-d5f522efa4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.9)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys - Replace with your actual keys\n",
        "GOOGLE_API_KEY = \"\"\n",
        "OPENAI_API_KEY = \"\""
      ],
      "metadata": {
        "id": "de2ywnBvrnjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except:\n",
        "    print(\"Installing spaCy model...\")\n",
        "    os.system(\"python -m spacy download en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@dataclass\n",
        "class Business:\n",
        "    business_name: str\n",
        "    address: str\n",
        "    website: str\n",
        "    skill_ids: List[str]\n",
        "    skill_names: List[str]\n",
        "\n",
        "class DirectoryManager:\n",
        "    \"\"\"Manages the directory structure and file operations\"\"\"\n",
        "    def __init__(self, base_path: str = \"/content/drive/MyDrive/Kobeyo Business Directory\"):\n",
        "        self.base_path = base_path\n",
        "        self.output_folder = os.path.join(base_path, \"Output\")\n",
        "        self.skill_tags_folder = os.path.join(base_path, \"Skill tag sheets\")\n",
        "\n",
        "        # Ensure directories exist\n",
        "        os.makedirs(self.output_folder, exist_ok=True)\n",
        "        os.makedirs(self.skill_tags_folder, exist_ok=True)\n",
        "\n",
        "        # Hardcoded business groups mapping\n",
        "        self.business_groups = {\n",
        "            \"Animal Care & Services\": [\"Pet walking\", \"Pet grooming\", \"Pet Boarding & Pet Sitting\", \"Vetinary Services\", \"Pet Training\", \"Animal Shelter\"],\n",
        "            \"Food & Beverage Establishments\": [\"Restaurants\", \"Quick Service Restaurants\", \"Bakeries\", \"Donuts\", \"Pastery Shops\", \"Sushi\", \"Cafes\", \"Coffee Roasters\", \"Breweries\", \"Distilleries\", \"Wine Bars\", \"Bars\", \"Sandwich Shops\", \"Tacos\", \"Bars (exclude grocery stores)\", \"Ice cream\"],\n",
        "            \"Real Estate & Property Management\": [\"Real Estate Agencies\", \"Escrow Services\", \"Title Services\", \"Property Management\"],\n",
        "            \"Cleaning & Remediation\": [\"maid services\", \"house cleaning services\", \"office cleaning services\", \"commercial cleaning services\", \"Dry cleaning\", \"Specialty cleaning services\", \"fire water and mold restoration\", \"HAZMAT cleaning services\", \"Window cleaning services\", \"Pool cleaning\", \"Carpet & upholstry cleaning services\", \"Grease trap cleaning\", \"Portable toilets services\", \"Septic cleaning services\"],\n",
        "            \"Security\": [\"Security Services\", \"Security Alarms\", \"Fire Alarms\"],\n",
        "            \"Logistics, Warehousing & Distribution\": [\"Last Mile Delivery\", \"Couriier Services\", \"Long Haul Trucking\", \"Warehouse\", \"Distribution Center\", \"Logistics\", \"Ports\", \"Distribution\", \"Dispatch & Routing\", \"Transport Services\", \"Limo Services\", \"Shuttle Services\", \"Pet Taxi\", \"Delivery Specialist\", \"Cannabis Delivery Specialis\", \"Freight brokerage services\"],\n",
        "            \"Landscaping, Groundskeeping & Pest Control\": [\"Landscape Architects & Design Firms\", \"Landscapers\", \"Landscape Construction\", \"Tree Trimming Services\", \"Tree Specialists\", \"Pest Control\", \"Golf Course\", \"Pool Builder\", \"Pool Maintenance & Service\"],\n",
        "            \"Bookkeeping, Accounting & Payroll Services\": [\"Bookkeeping\", \"Payroll\", \"Accounting Firms\", \"Personal Accountants\"],\n",
        "            \"Recruiting & Staffing Agencies\": [\"Staffing & recruiting house cleaning\", \"Industrial Staffing & Recruiting\", \"Staffing & Recruiting Services\", \"Recruiter\", \"Accounting & Payroll Staffing & Recruiting\", \"Customer Service Staffing & Recruiting\", \"Sales Staffing & Recruiting\", \"Admin Staffing & Recruiting\", \"Manufacturing Staffing & Recruiting\", \"Security Staffing\", \"Video & Audio Production Staffing & Recruiting\", \"Property Management Staffing & Recruiting\", \"Staffing & Recruiting Mechanics\"]\n",
        "        }\n",
        "\n",
        "    def get_business_group_from_type(self, business_type: str) -> Optional[str]:\n",
        "        \"\"\"Find the business group based on business type\"\"\"\n",
        "        business_type_lower = business_type.lower()\n",
        "\n",
        "        for group_name, business_types in self.business_groups.items():\n",
        "            for biz_type in business_types:\n",
        "                if business_type_lower in biz_type.lower() or biz_type.lower() in business_type_lower:\n",
        "                    return group_name\n",
        "\n",
        "        print(f\"⚠️ No business group found for type: {business_type}\")\n",
        "        return None\n",
        "\n",
        "    def get_all_business_types_in_group(self, group_name: str) -> List[str]:\n",
        "        \"\"\"Get all business types under a specific group\"\"\"\n",
        "        return self.business_groups.get(group_name, [])\n",
        "\n",
        "    def load_skill_tags_for_group(self, group_name: str) -> pd.DataFrame:\n",
        "        \"\"\"Load skill tags for a specific business group\"\"\"\n",
        "        try:\n",
        "            # Construct the skill tags file path\n",
        "            skill_file_path = os.path.join(self.skill_tags_folder, f\"skill tags - {group_name}.csv\")\n",
        "\n",
        "            if not os.path.exists(skill_file_path):\n",
        "                print(f\"⚠️ Skill tags file not found: {skill_file_path}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            df = pd.read_csv(skill_file_path)\n",
        "            print(f\"✅ Loaded skill tags for {group_name} with {len(df)} entries\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading skill tags for {group_name}: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def get_output_file_path(self, group_name: str) -> str:\n",
        "        \"\"\"Get the output file path for a specific business group\"\"\"\n",
        "        return os.path.join(self.output_folder, f\"businesses_{group_name.replace(' ', '_').replace('&', 'and')}.csv\")\n",
        "\n",
        "class NERBusinessScraper:\n",
        "    def __init__(self, google_api_key: str):\n",
        "        self.google_api_key = google_api_key\n",
        "        self.places_base_url = \"https://maps.googleapis.com/maps/api/place\"\n",
        "        self.directory_manager = DirectoryManager()\n",
        "        self.current_group = None\n",
        "        self.current_skill_tags_df = pd.DataFrame()\n",
        "        self.setup_driver()\n",
        "\n",
        "    def setup_driver(self):\n",
        "        \"\"\"Setup Chrome driver for web scraping\"\"\"\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def extract_skills_with_ner(self, text: str) -> Dict[str, List[str]]:\n",
        "        \"\"\"Extract skills using basic NER and keyword matching\"\"\"\n",
        "        if self.current_skill_tags_df.empty:\n",
        "            return {\"skill_ids\": [], \"skill_names\": []}\n",
        "\n",
        "        # Process text with spaCy\n",
        "        doc = nlp(text.lower())\n",
        "\n",
        "        # Extract entities and keywords\n",
        "        entities = [ent.text for ent in doc.ents]\n",
        "        tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "        # Combine entities and tokens for matching\n",
        "        text_features = set(entities + tokens)\n",
        "\n",
        "        matched_skills = {\"skill_ids\": [], \"skill_names\": []}\n",
        "\n",
        "        # Match against skill tags\n",
        "        for _, row in self.current_skill_tags_df.iterrows():\n",
        "            skill_id = str(row.get('Skills IDs', row.get('skill_ids', '')))\n",
        "            skill_name = str(row.get('Skills Names', row.get('skill_names', '')))\n",
        "\n",
        "            # Check if skill name appears in text\n",
        "            if skill_name.lower() in text.lower():\n",
        "                matched_skills[\"skill_ids\"].append(skill_id)\n",
        "                matched_skills[\"skill_names\"].append(skill_name)\n",
        "                continue\n",
        "\n",
        "            # Check for keyword matches\n",
        "            skill_keywords = skill_name.lower().split()\n",
        "            if any(keyword in text_features for keyword in skill_keywords):\n",
        "                matched_skills[\"skill_ids\"].append(skill_id)\n",
        "                matched_skills[\"skill_names\"].append(skill_name)\n",
        "\n",
        "        return matched_skills\n",
        "\n",
        "    def scrape_website_content(self, url: str) -> str:\n",
        "        \"\"\"Scrape website content for skill extraction\"\"\"\n",
        "        if not url:\n",
        "            return \"\"\n",
        "\n",
        "        try:\n",
        "            if not url.startswith(('http://', 'https://')):\n",
        "                url = 'https://' + url\n",
        "\n",
        "            self.driver.get(url)\n",
        "            time.sleep(3)\n",
        "\n",
        "            page_source = self.driver.page_source\n",
        "            soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "            # Extract text content\n",
        "            text_content = soup.get_text()\n",
        "\n",
        "            # Focus on first 2000 characters\n",
        "            return text_content[:2000]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping website {url}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def search_businesses(self, query: str, location: str = \"Los Angeles, CA\", max_results: int = 10) -> List[Dict]:\n",
        "        \"\"\"Search for businesses using Google Places API\"\"\"\n",
        "        url = f\"{self.places_base_url}/textsearch/json\"\n",
        "        params = {\n",
        "            'query': f\"{query} in {location}\",\n",
        "            'key': self.google_api_key,\n",
        "            'type': 'establishment'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Google Places API error: {response.status_code}\")\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get(\"status\") != \"OK\":\n",
        "            if data.get(\"status\") == \"ZERO_RESULTS\":\n",
        "                return []\n",
        "            raise Exception(f\"Google Places API error: {data.get('error_message', 'Unknown error')}\")\n",
        "\n",
        "        return data.get(\"results\", [])[:max_results]\n",
        "\n",
        "    def get_business_details(self, place_id: str) -> Dict:\n",
        "        \"\"\"Get detailed information about a specific business\"\"\"\n",
        "        details_url = f\"{self.places_base_url}/details/json\"\n",
        "        params = {\n",
        "            \"place_id\": place_id,\n",
        "            \"fields\": \"name,formatted_address,website\",\n",
        "            \"key\": self.google_api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(details_url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data.get(\"status\") == \"OK\":\n",
        "                return data.get(\"result\", {})\n",
        "\n",
        "        return {}\n",
        "\n",
        "    def process_business(self, place_data: Dict) -> Business:\n",
        "        \"\"\"Process a single business and create Business object\"\"\"\n",
        "        place_id = place_data.get(\"place_id\")\n",
        "        details = self.get_business_details(place_id) if place_id else {}\n",
        "\n",
        "        # Merge basic and detailed data\n",
        "        business_info = {**place_data, **details}\n",
        "\n",
        "        # Get website\n",
        "        website = business_info.get(\"website\", \"\")\n",
        "\n",
        "        # Scrape website content for skills\n",
        "        website_content = self.scrape_website_content(website) if website else \"\"\n",
        "\n",
        "        # Extract skills using NER\n",
        "        skill_info = self.extract_skills_with_ner(website_content)\n",
        "\n",
        "        return Business(\n",
        "            business_name=business_info.get(\"name\", \"\"),\n",
        "            address=business_info.get(\"formatted_address\", \"\"),\n",
        "            website=website,\n",
        "            skill_ids=skill_info.get(\"skill_ids\", []),\n",
        "            skill_names=skill_info.get(\"skill_names\", [])\n",
        "        )\n",
        "\n",
        "    def scrape_businesses_by_group(self, business_type: str, location: str = \"Los Angeles, CA\", max_results: int = 10) -> List[Business]:\n",
        "        \"\"\"Main method to scrape businesses with group-based categorization\"\"\"\n",
        "        print(f\"🔍 Analyzing business type: '{business_type}' in {location}\")\n",
        "\n",
        "        # Get business group\n",
        "        group_name = self.directory_manager.get_business_group_from_type(business_type)\n",
        "        if not group_name:\n",
        "            print(f\"⚠️ No group found for {business_type}\")\n",
        "            return []\n",
        "\n",
        "        # Load skill tags\n",
        "        self.current_group = group_name\n",
        "        self.current_skill_tags_df = self.directory_manager.load_skill_tags_for_group(group_name)\n",
        "\n",
        "        # Get business types in group\n",
        "        all_business_types = self.directory_manager.get_all_business_types_in_group(group_name)\n",
        "\n",
        "        # Search for businesses\n",
        "        all_businesses = []\n",
        "        for biz_type in all_business_types[:2]:  # Limit to 2 types\n",
        "            print(f\"🔍 Searching for: {biz_type}\")\n",
        "            try:\n",
        "                places = self.search_businesses(biz_type, location, max_results//2)\n",
        "\n",
        "                for place in places:\n",
        "                    business_name = place.get('name', 'Unknown')\n",
        "                    print(f\"Processing: {business_name}\")\n",
        "\n",
        "                    try:\n",
        "                        business = self.process_business(place)\n",
        "                        all_businesses.append(business)\n",
        "                        time.sleep(1)  # Rate limiting\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {business_name}: {e}\")\n",
        "                        continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error searching for {biz_type}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return all_businesses\n",
        "\n",
        "    def save_results(self, businesses: List[Business]):\n",
        "        \"\"\"Save results to CSV file\"\"\"\n",
        "        if not businesses or not self.current_group:\n",
        "            print(\"❌ No businesses to save\")\n",
        "            return\n",
        "\n",
        "        output_file_path = self.directory_manager.get_output_file_path(self.current_group)\n",
        "\n",
        "        with open(output_file_path, 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(['business_name', 'address', 'website', 'skill_ids', 'skill_names'])\n",
        "\n",
        "            for business in businesses:\n",
        "                writer.writerow([\n",
        "                    business.business_name,\n",
        "                    business.address,\n",
        "                    business.website,\n",
        "                    '; '.join(business.skill_ids),\n",
        "                    '; '.join(business.skill_names)\n",
        "                ])\n",
        "\n",
        "        print(f\"✅ Results saved to {output_file_path}\")\n",
        "\n",
        "    def display_results(self, businesses: List[Business]):\n",
        "        \"\"\"Display results\"\"\"\n",
        "        if not businesses:\n",
        "            print(\"❌ No businesses found\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n🎯 Found {len(businesses)} businesses\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        for i, business in enumerate(businesses, 1):\n",
        "            print(f\"\\n{i}. {business.business_name}\")\n",
        "            print(f\"   Address: {business.address}\")\n",
        "            print(f\"   Website: {business.website}\")\n",
        "            print(f\"   Skills: {', '.join(business.skill_names)}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Clean up selenium driver\"\"\"\n",
        "        if hasattr(self, 'driver'):\n",
        "            self.driver.quit()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function\"\"\"\n",
        "    business_type = input(\"Enter business type: \").strip()\n",
        "    location = input(\"Enter location: \").strip()\n",
        "\n",
        "    if not business_type:\n",
        "        business_type = \"restaurant\"\n",
        "    if not location:\n",
        "        location = \"Los Angeles, CA\"\n",
        "\n",
        "    scraper = NERBusinessScraper(GOOGLE_API_KEY)\n",
        "\n",
        "    try:\n",
        "        businesses = scraper.scrape_businesses_by_group(business_type, location)\n",
        "        scraper.display_results(businesses)\n",
        "        scraper.save_results(businesses)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ht1NfLwDgX",
        "outputId": "a6aac6dd-e800-47ee-8274-2b96d60f540c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter business type: animal care\n",
            "Enter location: LA\n",
            "🔍 Analyzing business type: 'animal care' in LA\n",
            "⚠️ No business group found for type: animal care\n",
            "⚠️ No group found for animal care\n",
            "❌ No businesses found\n",
            "❌ No businesses to save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYuHKNXy1yGv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}