{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rc2Kl12N5TY",
        "outputId": "f9c43d96-7088-4601-902f-95537bd0d329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.6.15)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googlemaps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHJZPWnDN6BN",
        "outputId": "4c4dfced-9f87-4322-e796-257e12b62f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googlemaps in /usr/local/lib/python3.11/dist-packages (4.10.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from googlemaps) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "import openai\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Any\n",
        "from datetime import datetime\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from google.colab import drive\n",
        "import urllib.parse"
      ],
      "metadata": {
        "id": "5F3210xJN6Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys - Replace with your actual keys\n",
        "GOOGLE_API_KEY = \"\"\n",
        "OPENAI_API_KEY = \"\""
      ],
      "metadata": {
        "id": "OIiu7tfaN6HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Business:\n",
        "    place_id: str\n",
        "    business_name: str\n",
        "    address: str\n",
        "    phone_number: Optional[str] = None\n",
        "    latitude: Optional[float] = None\n",
        "    longitude: Optional[float] = None\n",
        "    website: Optional[str] = None\n",
        "    hr_email: Optional[str] = None\n",
        "    sales_email: Optional[str] = None\n",
        "    careers_page: Optional[str] = None\n",
        "    sales_page: Optional[str] = None\n",
        "    social_media_links: Dict[str, str] = None\n",
        "    business_type: List[str] = None\n",
        "    skill_ids: List[str] = None\n",
        "    skill_names: List[str] = None"
      ],
      "metadata": {
        "id": "K_y7vZOnN6Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DirectoryManager:\n",
        "    \"\"\"Manages the directory structure and file operations\"\"\"\n",
        "\n",
        "    def __init__(self, base_path: str = \"/content/drive/MyDrive/Kobeyo Business Directory\"):\n",
        "        self.base_path = base_path\n",
        "        self.output_folder = os.path.join(base_path, \"Output\")\n",
        "        self.skill_tags_folder = os.path.join(base_path, \"Skill tag sheets\")\n",
        "        self.business_groups_file = os.path.join(base_path, \"Extracted_Business_Groups_and_Types.csv\")\n",
        "\n",
        "        # Ensure directories exist\n",
        "        os.makedirs(self.output_folder, exist_ok=True)\n",
        "        os.makedirs(self.skill_tags_folder, exist_ok=True)\n",
        "\n",
        "    def get_business_group_from_type(self, business_type: str) -> Optional[str]:\n",
        "        \"\"\"Find the business group based on business type from the main CSV\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(self.business_groups_file):\n",
        "                print(f\"‚ùå Business groups file not found: {self.business_groups_file}\")\n",
        "                return None\n",
        "\n",
        "            df = pd.read_csv(self.business_groups_file)\n",
        "\n",
        "            # Search for business type in the CSV\n",
        "            for _, row in df.iterrows():\n",
        "                # Check if business type matches any column that contains business types\n",
        "                for col in df.columns:\n",
        "                    if pd.notna(row[col]) and business_type.lower() in str(row[col]).lower():\n",
        "                        # Return the group name (assuming first column is the group name)\n",
        "                        return str(row.iloc[0])\n",
        "\n",
        "            print(f\"‚ö†Ô∏è No business group found for type: {business_type}\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error reading business groups file: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_all_business_types_in_group(self, group_name: str) -> List[str]:\n",
        "        \"\"\"Get all business types under a specific group\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(self.business_groups_file):\n",
        "                return []\n",
        "\n",
        "            df = pd.read_csv(self.business_groups_file)\n",
        "\n",
        "            # Find the row with the group name\n",
        "            group_row = df[df.iloc[:, 0].str.contains(group_name, case=False, na=False)]\n",
        "\n",
        "            if group_row.empty:\n",
        "                return []\n",
        "\n",
        "            # Extract all business types from the row (excluding the group name column)\n",
        "            business_types = []\n",
        "            for col in df.columns[1:]:  # Skip first column (group name)\n",
        "                value = group_row.iloc[0][col]\n",
        "                if pd.notna(value) and str(value).strip():\n",
        "                    business_types.append(str(value).strip())\n",
        "\n",
        "            return business_types\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting business types for group {group_name}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def load_skill_tags_for_group(self, group_name: str) -> pd.DataFrame:\n",
        "        \"\"\"Load skill tags for a specific business group\"\"\"\n",
        "        try:\n",
        "            # Construct the skill tags file path\n",
        "            skill_file_path = os.path.join(self.skill_tags_folder, f\"skill tags - {group_name}.csv\")\n",
        "\n",
        "            if not os.path.exists(skill_file_path):\n",
        "                print(f\"‚ö†Ô∏è Skill tags file not found: {skill_file_path}\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            df = pd.read_csv(skill_file_path)\n",
        "            print(f\"‚úÖ Loaded skill tags for {group_name} with {len(df)} entries\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading skill tags for {group_name}: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def get_output_file_path(self, group_name: str) -> str:\n",
        "        \"\"\"Get the output file path for a specific business group\"\"\"\n",
        "        return os.path.join(self.output_folder, f\"businesses_{group_name.replace(' ', '_').replace('&', 'and')}.csv\")\n"
      ],
      "metadata": {
        "id": "5MczG-N6N6No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartBusinessScraper:\n",
        "    def __init__(self, google_api_key: str, openai_api_key: str):\n",
        "        self.google_api_key = google_api_key\n",
        "        self.openai_client = openai.OpenAI(api_key=openai_api_key)\n",
        "        self.places_base_url = \"https://maps.googleapis.com/maps/api/place\"\n",
        "        self.website_context = {}  # Store scraped website context\n",
        "\n",
        "        # Initialize directory manager\n",
        "        self.directory_manager = DirectoryManager()\n",
        "\n",
        "        # Current business group context\n",
        "        self.current_group = None\n",
        "        self.current_skill_tags_df = pd.DataFrame()\n",
        "\n",
        "        # Mount Google Drive if not already mounted\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            drive.mount('/content/drive')\n",
        "        elif not os.path.ismount('/content/drive'):\n",
        "             drive.mount('/content/drive')\n",
        "        else:\n",
        "            print(\"Google Drive is already mounted.\")\n",
        "\n",
        "\n",
        "        # Setup selenium driver\n",
        "        self.setup_driver()\n",
        "\n",
        "    def setup_driver(self):\n",
        "        \"\"\"Setup Chrome driver for web scraping\"\"\"\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "        chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def categorize_business_type(self, business_type: str, location: str) -> Dict[str, Any]:\n",
        "        \"\"\"Categorize business type and load appropriate skill tags\"\"\"\n",
        "        # Find the business group for this type\n",
        "        group_name = self.directory_manager.get_business_group_from_type(business_type)\n",
        "\n",
        "        if not group_name:\n",
        "            print(f\"‚ö†Ô∏è Using fallback: searching for similar business types\")\n",
        "            return self.fallback_categorization(business_type)\n",
        "\n",
        "        # Get all business types in this group\n",
        "        all_business_types = self.directory_manager.get_all_business_types_in_group(group_name)\n",
        "\n",
        "        # Load skill tags for this group\n",
        "        skill_tags_df = self.directory_manager.load_skill_tags_for_group(group_name)\n",
        "\n",
        "        # Update current context\n",
        "        self.current_group = group_name\n",
        "        self.current_skill_tags_df = skill_tags_df\n",
        "\n",
        "        return {\n",
        "            \"group_name\": group_name,\n",
        "            \"all_business_types\": all_business_types,\n",
        "            \"skill_tags_loaded\": not skill_tags_df.empty,\n",
        "            \"skill_tags_count\": len(skill_tags_df)\n",
        "        }\n",
        "\n",
        "    def fallback_categorization(self, business_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"Fallback method when business type is not found in the main CSV\"\"\"\n",
        "        # Try to guess the group based on common keywords\n",
        "        group_mappings = {\n",
        "            \"food\": [\"restaurant\", \"cafe\", \"bakery\", \"bar\", \"catering\"],\n",
        "            \"cleaning\": [\"cleaning\", \"janitorial\", \"maintenance\", \"housekeeping\"],\n",
        "            \"animal care\": [\"veterinary\", \"pet\", \"animal\", \"grooming\"]\n",
        "        }\n",
        "\n",
        "        business_type_lower = business_type.lower()\n",
        "\n",
        "        for group, keywords in group_mappings.items():\n",
        "            if any(keyword in business_type_lower for keyword in keywords):\n",
        "                skill_tags_df = self.directory_manager.load_skill_tags_for_group(group.title())\n",
        "                self.current_group = group.title()\n",
        "                self.current_skill_tags_df = skill_tags_df\n",
        "\n",
        "                return {\n",
        "                    \"group_name\": group.title(),\n",
        "                    \"all_business_types\": [business_type],\n",
        "                    \"skill_tags_loaded\": not skill_tags_df.empty,\n",
        "                    \"skill_tags_count\": len(skill_tags_df),\n",
        "                    \"fallback_used\": True\n",
        "                }\n",
        "\n",
        "        # If no match found, use generic approach\n",
        "        self.current_group = \"Generic\"\n",
        "        self.current_skill_tags_df = pd.DataFrame()\n",
        "\n",
        "        return {\n",
        "            \"group_name\": \"Generic\",\n",
        "            \"all_business_types\": [business_type],\n",
        "            \"skill_tags_loaded\": False,\n",
        "            \"skill_tags_count\": 0,\n",
        "            \"fallback_used\": True\n",
        "        }\n",
        "\n",
        "    def scrape_website_content(self, url: str) -> str:\n",
        "        \"\"\"Scrape website content to extract skills-related information\"\"\"\n",
        "        if not url:\n",
        "            return \"\"\n",
        "\n",
        "        try:\n",
        "            # Normalize URL\n",
        "            if not url.startswith(('http://', 'https://')):\n",
        "                url = 'https://' + url\n",
        "\n",
        "            self.driver.get(url)\n",
        "            time.sleep(3)\n",
        "\n",
        "            # Get page content\n",
        "            page_source = self.driver.page_source\n",
        "            soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "            # Extract relevant text content\n",
        "            text_content = soup.get_text()\n",
        "\n",
        "            # Focus on skills-related content (first 2000 characters)\n",
        "            skills_context = text_content[:2000].lower()\n",
        "\n",
        "            # Store in memory\n",
        "            self.website_context[url] = skills_context\n",
        "\n",
        "            return skills_context\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping website {url}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def find_careers_and_sales_pages(self, website_url: str) -> Dict[str, str]:\n",
        "        \"\"\"Find careers and sales pages on the website\"\"\"\n",
        "        careers_page = None\n",
        "        sales_page = None\n",
        "\n",
        "        if not website_url:\n",
        "            return {\"careers_page\": careers_page, \"sales_page\": sales_page}\n",
        "\n",
        "        try:\n",
        "            if not website_url.startswith(('http://', 'https://')):\n",
        "                website_url = 'https://' + website_url\n",
        "\n",
        "            self.driver.get(website_url)\n",
        "            time.sleep(2)\n",
        "\n",
        "            # Look for careers/jobs links\n",
        "            careers_keywords = ['careers', 'jobs', 'employment', 'work-with-us', 'join-our-team']\n",
        "            for keyword in careers_keywords:\n",
        "                try:\n",
        "                    element = self.driver.find_element(By.PARTIAL_LINK_TEXT, keyword)\n",
        "                    careers_page = element.get_attribute('href')\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            # Look for sales/contact links\n",
        "            sales_keywords = ['sales', 'contact', 'get-quote', 'services', 'about']\n",
        "            for keyword in sales_keywords:\n",
        "                try:\n",
        "                    element = self.driver.find_element(By.PARTIAL_LINK_TEXT, keyword)\n",
        "                    sales_page = element.get_attribute('href')\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error finding pages on {website_url}: {e}\")\n",
        "\n",
        "        return {\"careers_page\": careers_page, \"sales_page\": sales_page}\n",
        "\n",
        "    def extract_emails_and_social_media(self, website_url: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extract emails and social media links from website\"\"\"\n",
        "        hr_email = None\n",
        "        sales_email = None\n",
        "        social_media = {\"facebook\": None, \"instagram\": None, \"linkedin\": None}\n",
        "\n",
        "        if not website_url:\n",
        "            return {\"hr_email\": hr_email, \"sales_email\": sales_email, \"social_media\": social_media}\n",
        "\n",
        "        try:\n",
        "            if not website_url.startswith(('http://', 'https://')):\n",
        "                website_url = 'https://' + website_url\n",
        "\n",
        "            self.driver.get(website_url)\n",
        "            time.sleep(2)\n",
        "\n",
        "            page_source = self.driver.page_source\n",
        "\n",
        "            # Extract emails\n",
        "            email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
        "            emails = re.findall(email_pattern, page_source)\n",
        "\n",
        "            for email in emails:\n",
        "                email_lower = email.lower()\n",
        "                if any(keyword in email_lower for keyword in ['hr', 'jobs', 'careers', 'hiring']):\n",
        "                    hr_email = email\n",
        "                elif any(keyword in email_lower for keyword in ['sales', 'contact', 'info', 'hello']):\n",
        "                    sales_email = email\n",
        "\n",
        "            # Extract social media links\n",
        "            social_patterns = {\n",
        "                'facebook': r'https?://(?:www\\.)?facebook\\.com/[^/\\s]+',\n",
        "                'instagram': r'https?://(?:www\\.)?instagram\\.com/[^/\\s]+',\n",
        "                'linkedin': r'https?://(?:www\\.)?linkedin\\.com/[^/\\s]+'\n",
        "            }\n",
        "\n",
        "            for platform, pattern in social_patterns.items():\n",
        "                matches = re.findall(pattern, page_source)\n",
        "                if matches:\n",
        "                    social_media[platform] = matches[0]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting emails/social media from {website_url}: {e}\")\n",
        "\n",
        "        return {\"hr_email\": hr_email, \"sales_email\": sales_email, \"social_media\": social_media}\n",
        "\n",
        "    def search_businesses(self, query: str, location: str = \"Los Angeles, CA\", max_results: int = 10) -> List[Dict]:\n",
        "        \"\"\"Search for businesses using Google Places API\"\"\"\n",
        "        url = f\"{self.places_base_url}/textsearch/json\"\n",
        "        params = {\n",
        "            'query': f\"{query} in {location}\",\n",
        "            'key': self.google_api_key,\n",
        "            'type': 'establishment'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Google Places API error: {response.status_code}\")\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get(\"status\") != \"OK\":\n",
        "            if data.get(\"status\") == \"ZERO_RESULTS\":\n",
        "                return []\n",
        "            raise Exception(f\"Google Places API error: {data.get('error_message', 'Unknown error')}\")\n",
        "\n",
        "        return data.get(\"results\", [])[:max_results]\n",
        "\n",
        "    def get_business_details(self, place_id: str) -> Dict:\n",
        "        \"\"\"Get detailed information about a specific business\"\"\"\n",
        "        details_url = f\"{self.places_base_url}/details/json\"\n",
        "        params = {\n",
        "            \"place_id\": place_id,\n",
        "            \"fields\": \"name,formatted_address,geometry,website,formatted_phone_number,business_status,opening_hours,rating,reviews,types\",\n",
        "            \"key\": self.google_api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(details_url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data.get(\"status\") == \"OK\":\n",
        "                return data.get(\"result\", {})\n",
        "\n",
        "        return {}\n",
        "\n",
        "    def get_relevant_skills_from_group(self, business_types: List[str]) -> str:\n",
        "        \"\"\"Get relevant skills from the loaded skill tags DataFrame\"\"\"\n",
        "        if self.current_skill_tags_df.empty:\n",
        "            return \"No skill tags available for this business group\"\n",
        "\n",
        "        try:\n",
        "            # Get all available skills for this group\n",
        "            skills_text = \"\"\n",
        "\n",
        "            # Limit to first 10 skills to avoid token limits\n",
        "            for _, row in self.current_skill_tags_df.head(10).iterrows():\n",
        "                skill_id = row.get('Skills IDs', row.get('skill_ids', 'N/A'))\n",
        "                skill_name = row.get('Skills Names', row.get('skill_names', 'N/A'))\n",
        "                prompt_rule = row.get('Prompt Rule', row.get('prompt_rule', 'N/A'))\n",
        "\n",
        "                skills_text += f\"ID: {skill_id}, Name: {skill_name}, Rule: {str(prompt_rule)[:100]}...\\n\"\n",
        "\n",
        "            return skills_text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing skills from group: {e}\")\n",
        "            return \"Error processing skills from group CSV\"\n",
        "\n",
        "    def tag_skills_with_ai(self, business_info: Dict, website_context: str) -> Dict[str, Any]:\n",
        "        \"\"\"Use OpenAI to tag skills based on business information and loaded skill tags\"\"\"\n",
        "        business_name = business_info.get(\"name\", \"\")\n",
        "        business_types = business_info.get(\"types\", [])\n",
        "\n",
        "        # Get relevant skills from the loaded group\n",
        "        relevant_skills = self.get_relevant_skills_from_group(business_types)\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = f\"\"\"\n",
        "Business: {business_name}\n",
        "Types: {', '.join(business_types[:3])}\n",
        "Context: {website_context[:200]}\n",
        "Business Group: {self.current_group}\n",
        "\n",
        "Available Skills for this group:\n",
        "{relevant_skills}\n",
        "\n",
        "Based on this business info, return relevant skill IDs and names as JSON:\n",
        "{{\n",
        "  \"skill_ids\": [\"id1\", \"id2\"],\n",
        "  \"skill_names\": [\"name1\", \"name2\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.openai_client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Tag business skills using the provided group-specific skills. Respond with valid JSON only.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=200\n",
        "            )\n",
        "\n",
        "            content = response.choices[0].message.content\n",
        "            json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "\n",
        "            if json_match:\n",
        "                return json.loads(json_match.group())\n",
        "            else:\n",
        "                return json.loads(content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"AI skill tagging error: {e}\")\n",
        "            return {\"skill_ids\": [], \"skill_names\": []}\n",
        "\n",
        "    def process_business(self, place_data: Dict) -> Business:\n",
        "        \"\"\"Process a single business and create Business object\"\"\"\n",
        "        place_id = place_data.get(\"place_id\")\n",
        "        details = self.get_business_details(place_id) if place_id else {}\n",
        "\n",
        "        # Merge basic and detailed data\n",
        "        business_info = {**place_data, **details}\n",
        "\n",
        "        # Get website\n",
        "        website = business_info.get(\"website\")\n",
        "\n",
        "        # Scrape website content for skills context\n",
        "        website_context = self.scrape_website_content(website) if website else \"\"\n",
        "\n",
        "        # Find careers and sales pages\n",
        "        pages_info = self.find_careers_and_sales_pages(website)\n",
        "\n",
        "        # Extract emails and social media\n",
        "        contact_info = self.extract_emails_and_social_media(website)\n",
        "\n",
        "        # Get AI skill tagging\n",
        "        skill_info = self.tag_skills_with_ai(business_info, website_context)\n",
        "\n",
        "        # Extract location\n",
        "        geometry = business_info.get(\"geometry\", {})\n",
        "        location = geometry.get(\"location\", {})\n",
        "\n",
        "        return Business(\n",
        "            place_id=place_id,\n",
        "            business_name=business_info.get(\"name\", \"\"),\n",
        "            address=business_info.get(\"formatted_address\", \"\"),\n",
        "            phone_number=business_info.get(\"formatted_phone_number\"),\n",
        "            latitude=location.get(\"lat\"),\n",
        "            longitude=location.get(\"lng\"),\n",
        "            website=website,\n",
        "            hr_email=contact_info.get(\"hr_email\"),\n",
        "            sales_email=contact_info.get(\"sales_email\"),\n",
        "            careers_page=pages_info.get(\"careers_page\"),\n",
        "            sales_page=pages_info.get(\"sales_page\"),\n",
        "            social_media_links=contact_info.get(\"social_media\"),\n",
        "            business_type=business_info.get(\"types\", []),\n",
        "            skill_ids=skill_info.get(\"skill_ids\", []),\n",
        "            skill_names=skill_info.get(\"skill_names\", [])\n",
        "        )\n",
        "\n",
        "    def scrape_businesses_by_group(self, business_type: str, location: str = \"Los Angeles, CA\", max_results: int = 10) -> List[Business]:\n",
        "        \"\"\"Main method to scrape businesses with group-based categorization\"\"\"\n",
        "        print(f\"üîç Analyzing business type: '{business_type}' in {location}\")\n",
        "\n",
        "        # Step 1: Categorize the business type and load appropriate resources\n",
        "        categorization_result = self.categorize_business_type(business_type, location)\n",
        "        print(f\"üìä Categorization result: {categorization_result}\")\n",
        "\n",
        "        # Step 2: Get all business types in the group for comprehensive searching\n",
        "        all_business_types = categorization_result[\"all_business_types\"]\n",
        "        print(f\"üè¢ Business types in group: {all_business_types}\")\n",
        "\n",
        "        # Step 3: Search for businesses using all types in the group\n",
        "        all_businesses = []\n",
        "\n",
        "        for biz_type in all_business_types[:3]:  # Limit to prevent too many API calls\n",
        "            print(f\"üîç Searching for: {biz_type}\")\n",
        "            try:\n",
        "                places = self.search_businesses(biz_type, location, max_results//len(all_business_types[:3]))\n",
        "\n",
        "                for place in places:\n",
        "                    business_name = place.get('name', 'Unknown')\n",
        "                    print(f\"Processing: {business_name}\")\n",
        "\n",
        "                    try:\n",
        "                        business = self.process_business(place)\n",
        "                        all_businesses.append(business)\n",
        "                        time.sleep(1)  # Rate limiting\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {business_name}: {e}\")\n",
        "                        continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error searching for {biz_type}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return all_businesses\n",
        "\n",
        "    def save_to_group_output(self, businesses: List[Business]):\n",
        "        \"\"\"Save results to the appropriate group output file\"\"\"\n",
        "        if not businesses or not self.current_group:\n",
        "            print(\"‚ùå No businesses to save or no group context\")\n",
        "            return\n",
        "\n",
        "        # Get the output file path for this group\n",
        "        output_file_path = self.directory_manager.get_output_file_path(self.current_group)\n",
        "\n",
        "        # Check if file exists to append or create new\n",
        "        file_exists = os.path.exists(output_file_path)\n",
        "\n",
        "        with open(output_file_path, 'a' if file_exists else 'w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "\n",
        "            # Write header only if file is new\n",
        "            if not file_exists:\n",
        "                writer.writerow([\n",
        "                    'place_id', 'business_name', 'address', 'phone_number', 'latitude', 'longitude',\n",
        "                    'website', 'hr_email', 'sales_email', 'careers_page', 'sales_page',\n",
        "                    'social_media_facebook', 'social_media_instagram', 'social_media_linkedin',\n",
        "                    'business_type', 'skill_ids', 'skill_names', 'business_group', 'scraped_date'\n",
        "                ])\n",
        "\n",
        "            # Write data\n",
        "            current_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            for business in businesses:\n",
        "                social_media = business.social_media_links or {}\n",
        "                writer.writerow([\n",
        "                    business.place_id,\n",
        "                    business.business_name,\n",
        "                    business.address,\n",
        "                    business.phone_number or '',\n",
        "                    business.latitude or '',\n",
        "                    business.longitude or '',\n",
        "                    business.website or '',\n",
        "                    business.hr_email or '',\n",
        "                    business.sales_email or '',\n",
        "                    business.careers_page or '',\n",
        "                    business.sales_page or '',\n",
        "                    social_media.get('facebook', ''),\n",
        "                    social_media.get('instagram', ''),\n",
        "                    social_media.get('linkedin', ''),\n",
        "                    '; '.join(business.business_type) if business.business_type else '',\n",
        "                    '; '.join(business.skill_ids) if business.skill_ids else '',\n",
        "                    '; '.join(business.skill_names) if business.skill_names else '',\n",
        "                    self.current_group,\n",
        "                    current_date\n",
        "                ])\n",
        "\n",
        "        print(f\"‚úÖ Results saved to {output_file_path}\")\n",
        "        print(f\"üìä Added {len(businesses)} businesses to the {self.current_group} group file\")\n",
        "\n",
        "    def display_results(self, businesses: List[Business]):\n",
        "        \"\"\"Display formatted results\"\"\"\n",
        "        if not businesses:\n",
        "            print(\"‚ùå No businesses found matching your criteria.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüéØ Found {len(businesses)} Businesses in {self.current_group} Group\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, business in enumerate(businesses, 1):\n",
        "            print(f\"\\n{i}. üè¢ {business.business_name}\")\n",
        "            print(f\"   Address: {business.address}\")\n",
        "            print(f\"   Website: {business.website or 'Not available'}\")\n",
        "            print(f\"   Phone: {business.phone_number or 'Not available'}\")\n",
        "            print(f\"   Skill IDs: {', '.join(business.skill_ids) if business.skill_ids else 'None'}\")\n",
        "            print(f\"   Skill Names: {', '.join(business.skill_names) if business.skill_names else 'None'}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Clean up selenium driver\"\"\"\n",
        "        if hasattr(self, 'driver'):\n",
        "            self.driver.quit()\n",
        "\n",
        "def get_user_input():\n",
        "    \"\"\"Get user input for business type and location\"\"\"\n",
        "    print(\"üîß Enhanced Smart Business Scraper\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    business_type = input(\"\\nEnter business type (e.g., 'restaurant', 'cafe', 'cleaning service'): \").strip()\n",
        "    location = input(\"Enter location (e.g., 'Los Angeles, CA', 'New York, NY'): \").strip()\n",
        "\n",
        "    if not business_type:\n",
        "        business_type = \"restaurant\"\n",
        "        print(f\"Using default business type: {business_type}\")\n",
        "\n",
        "    if not location:\n",
        "        location = \"Los Angeles, CA\"\n",
        "        print(f\"Using default location: {location}\")\n",
        "\n",
        "    return business_type, location\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the enhanced scraper\"\"\"\n",
        "    # Get user input\n",
        "    business_type, location = get_user_input()\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = SmartBusinessScraper(GOOGLE_API_KEY, OPENAI_API_KEY)\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nüîç Processing: {business_type} in {location}\")\n",
        "\n",
        "        # Use the new group-based scraping method\n",
        "        businesses = scraper.scrape_businesses_by_group(business_type, location, max_results=10)\n",
        "\n",
        "        # Display results\n",
        "        scraper.display_results(businesses)\n",
        "\n",
        "        # Save to group-specific output file\n",
        "        scraper.save_to_group_output(businesses)\n",
        "\n",
        "        print(f\"‚úÖ Completed processing for {scraper.current_group} group\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing '{business_type}' in '{location}': {e}\")\n",
        "\n",
        "    print(\"\\nüéâ Enhanced business scraping completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "P7sm9ZUXN6SF",
        "outputId": "552c073b-3aec-4925-c258-c2624877cc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Enhanced Smart Business Scraper\n",
            "========================================\n",
            "\n",
            "Enter business type (e.g., 'restaurant', 'cafe', 'cleaning service'): Cleaning services\n",
            "Enter location (e.g., 'Los Angeles, CA', 'New York, NY'): LA\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-40-2985439026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-40-2985439026.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;31m# Initialize scraper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mscraper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmartBusinessScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-40-2985439026.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, google_api_key, openai_api_key)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m              \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Google Drive is already mounted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    }
  ]
}